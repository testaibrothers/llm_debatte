import os, sys
# eine Ebene Ã¼ber 'app/' zum Modul-Suchpfad hinzufÃ¼gen
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import streamlit as st
from consensus.consensus_config import ConsensusConfig
from consensus.consensus import ConsensusOrchestrator
from agents.openai_adapter import OpenAIAdapter
from agents.gemini_adapter import GeminiAdapter

def main():
    st.set_page_config(page_title="KI-Debattenplattform", layout="centered")
    st.title("ðŸ¤– KI-Debattenplattform â€“ Modular")

    # Hilfetexte (einmal definiert)
    agent_provider_help = (
        "WÃ¤hle den KI-Anbieter fÃ¼r deinen Agenten aus. "
        "OpenAI ist weit verbreitet, Gemini ist Googles Modell. "
        "(Standard: OpenAI)"
    )
    agent_model_help = (
        "WÃ¤hle das Modell fÃ¼r die KI. GPT-4 liefert in der Regel genauere, "
        "komplexere Antworten als gpt-3.5-turbo, ist jedoch teurer und langsamer. "
        "(Standard: gpt-3.5-turbo)"
    )
    prompt_help = (
        "Definiere hier den System-Prompt, der das Verhalten der KI steuert. "
        "Beispiel: â€˜Du bist ein Finanzberater auf Topniveauâ€¦â€™. "
        "(Standard-Prompt vordefiniert)"
    )

    # â”€â”€ Sidebar: LLM-Einstellungen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar.expander("LLM-Einstellungen", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            provider_a = st.selectbox(
                "Agent A Anbieter", ["OpenAI", "Gemini"], index=0,
                help=agent_provider_help
            )
            model_a = st.selectbox(
                "Agent A Modell",
                ["gpt-3.5-turbo", "gpt-4"] if provider_a == "OpenAI" else ["gemini-proto"],
                index=0,
                help=agent_model_help
            )
            prompt_a = st.text_area(
                "Prompt Agent A",
                "Du bist ein Finanzberater auf Topniveauâ€¦",
                height=100,
                help=prompt_help
            )
        with col2:
            # FÃ¼r Gemini API-Key hinzufÃ¼gen
            provider_b = st.selectbox(
                "Agent B Anbieter", ["OpenAI", "Gemini"], index=0,
                help=agent_provider_help
            )
            model_b = st.selectbox(
                "Agent B Modell",
                ["gpt-3.5-turbo", "gpt-4"] if provider_b == "OpenAI" else ["gemini-proto"],
                index=0,
                help=agent_model_help
            )
            prompt_b = st.text_area(
                "Prompt Agent B",
                "Du bist ein Risikomanager auf Expert:innen-Levelâ€¦",
                height=100,
                help=prompt_help
            )

    # â”€â”€ Sidebar: Konsens-Einstellungen â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.sidebar.expander("Konsens-Einstellungen", expanded=False):
        cfg = ConsensusConfig()  # Standard-Defaults laden
        divergence_rounds = st.number_input(
            "Divergenz-Runden", 1, 20, value=cfg.divergence_rounds,
            help=(
                "Anzahl der Runden (Standard: 3), in denen die KIs abwechselnd "
                "neue Perspektiven liefern. Mehr Runden = mehr Vielfalt."
            )
        )
        divergence_threshold = st.slider(
            "Divergenz-Threshold", 0.0, 1.0, value=cfg.divergence_threshold,
            help=(
                "Steuert, wie unterschiedlich eine neue Antwort sein muss (Standard: 0.5). "
                "Geringere Werte = stÃ¤rker neue Ideen."
            )
        )
        convergence_threshold = st.slider(
            "Konvergenz-Threshold", 0.0, 1.0, value=cfg.convergence_threshold,
            help=(
                "Ab welchem Ã„hnlichkeitswert die Diskussion als Konsens gilt (Standard: 0.8). "
                "HÃ¶here Werte = strengere Einigung."
            )
        )
        max_total = st.number_input(
            "Max. Gesamt-BeitrÃ¤ge", 1, 50, value=cfg.max_rounds_total,
            help=(
                "Gesamtzahl der Nachrichten (Standard: 10), danach stoppt die Debatte automatisch."
            )
        )
        manual_pause = st.checkbox(
            "Manueller Stopp mÃ¶glich", value=cfg.manual_pause,
            help=(
                "ErmÃ¶glicht dir, die Debatte jederzeit per Button zu beenden."
            )
        )
        stop_on_manual = True

    # â”€â”€ Werte ins Config-Objekt schreiben â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    cfg.divergence_rounds = divergence_rounds
    cfg.divergence_threshold = divergence_threshold
    cfg.convergence_threshold = convergence_threshold
    cfg.max_rounds_total = max_total
    cfg.max_rounds = max_total               # legacy
    cfg.similarity_threshold = convergence_threshold  # legacy
    cfg.manual_pause = manual_pause
    cfg.stop_on_manual = stop_on_manual

    # â”€â”€ Agenten instanziieren â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    openai_key = st.secrets.get("openai_api_key", "")
    gemini_key = st.secrets.get("gemini_api_key", "")
    def make_agent(name, provider, model, prompt):
        if provider == "OpenAI":
            return OpenAIAdapter(name, openai_key, model=model, temperature=0.7)
        # FÃ¼r Gemini musst du in den App-Secrets 'gemini_api_key' setzen
        return GeminiAdapter(name, gemini_key, model=model)

    agent_a = make_agent("Agent A", provider_a, model_a, prompt_a)
    agent_b = make_agent("Agent B", provider_b, model_b, prompt_b)

    orchestrator = ConsensusOrchestrator(cfg)

    # â”€â”€ Hauptbereich: Thema eingeben & Diskussion starten â”€â”€â”€â”€
    topic = st.text_area("Thema / Idee", height=120)
    if st.button("Diskussion starten") and topic:
        history = orchestrator.run(agent_a, agent_b, initial_prompt=topic)
        # Finale Empfehlung anzeigen
        final_agent, final_text = history[-1]
        st.markdown("### Finale Empfehlung")
        st.markdown(f"**{final_agent}:** {final_text}")

if __name__ == "__main__":
    main()
